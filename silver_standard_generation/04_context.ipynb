{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Labelling functions\n",
    "\n",
    "Creating labeling functions based on the surrounding context of a word. Here we can use some prior knowledge from existing studies. Namely all rule-based (and maybe also some supervised methods) we identified in the review dealing with software extraction. The rules they used are exactly what is needed to create the weak supervision labels.\n",
    "Combining this set of rules can serve to be starting point. \n",
    "\n",
    "But first, lets set up the standard environment as always. For context we mainly can use the practical **Helper Functions** provided by snorkel.\n",
    "\n",
    "**Important**: the `test_LF` function is not imported, because it has hard coded queries and does not evaluate the results in a meaningful way.\n",
    "\n",
    "We also load the development set we use for evaluation purposes, so we do not have to calculate it more than once. \n",
    "\n",
    "Importing **spacy**, mainly because it lets us identify stop words and Snorkel is already built with spacy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from shutil import copy\n",
    "from functools import partial, update_wrapper \n",
    "\n",
    "BASE_NAME = 'Snorkel/SSC_0' \n",
    "DATABASE_NAME = 'SSC_0' \n",
    "LABELS_NAME = 'Snorkel/SSC_annotation' \n",
    "PARALLELISM = 1\n",
    "# os.environ['SNORKELDB'] = 'postgres://snorkel:snorkel@localhost/' + DATABASE_NAME\n",
    "# PARALLELISM = 64\n",
    "os.environ['SNORKELDB'] = 'sqlite:///' + DATABASE_NAME + '.db'\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.annotations import load_gold_labels\n",
    "from snorkel.learning.utils import MentionScorer\n",
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "set_mapping = {\n",
    "    'train': 0, \n",
    "    'test': 1,\n",
    "    'new': 2\n",
    "}\n",
    "\n",
    "from snorkel.lf_helpers import (\n",
    "    contains_token, get_between_tokens, get_doc_candidate_spans,\n",
    "    get_left_tokens, get_matches, get_right_tokens, \n",
    "    get_sent_candidate_spans, get_tagged_text, get_text_between, \n",
    "    get_text_splits, is_inverted\n",
    ")\n",
    "\n",
    "session = SnorkelSession()\n",
    "software = candidate_subclass('software', ['software'])\n",
    "devel_gold_labels = load_gold_labels(session, annotator_name='gold', split=set_mapping['train'])\n",
    "\n",
    "test_cands = session.query(software).filter(software.split==set_mapping['train']).all()\n",
    "test_labels = load_gold_labels(session, annotator_name=\"gold\", split=set_mapping['train'])\n",
    "scorer = MentionScorer(test_cands, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Functions\n",
    "\n",
    "Getting started:\n",
    "After all it comes down to two articles, which really deal with the topic and of extracting software mentions per rules.\n",
    "Here is the starting information this provides us with:\n",
    "\n",
    "### Pan et al.'s Assessing the Impact of Software on science most extracted patterns:\n",
    "`use <> software\n",
    "perform use <>\n",
    "be perform use <>\n",
    "analysis be perform use <>\n",
    "analyze use <>\n",
    "analysis be perform with <>\n",
    "<> statistical software\n",
    "<> software be use\n",
    "quantify use <>\n",
    "be calculate use <>`\n",
    "\n",
    "Those rules all require lemmatization.\n",
    "All of them need to be implemented separately.\n",
    "\n",
    "#### Implementing and testing\n",
    "\n",
    "##### All matches strategy\n",
    "Apparently Snorkel does in fact match all candidates, not just the longest or shortest one.. The problem becomes apparent with the second rule: For the sentence 'All processing was performed using ScopeWin and Matlab software.' we match 'ScopeWin', 'ScopeWin and', 'ScopeWin and Matlab' .., where only the first is a true positive and all others are true negatives. This means we do have to look at the individual tokens and determine if too much was matched. The strategy is desgined watching rule 2. \n",
    "- if a stop word is in the match it is discarded\n",
    "- Numbers (versions - regex: (\\d+\\.)?(\\d+\\.)?(\\*|\\d+) )\n",
    "- Version statement\n",
    "- Pretty much any punctuation\n",
    "- other likely keywords (this corresponds to head nouns, since we do not want to match them), so software, program, toolbox, etc. but also for other stuff: method, procedures, etc. \n",
    "- our old fried 'statistical'\n",
    "\n",
    "A similar problem presents itself with rule one. Since we have a left and right context, everything inbetween in matched. What means that in the case of 'we used the Matlab software', it will match 'the Matlab' instead of just 'Matlab'. However, we have to make sure that our matches are as accurate as possible. There are a number of solutions for this problem: \n",
    "- do not consider matches with stop words in them, of course on the other hand we have to view a larger context and remove stop words in order to be able to catch the right candidate.\n",
    "- aside stop words, 'statistical' is often mentioned before software, this should also be considered.\n",
    "- we can also include mentions that will reduce the number of false negatives, e.g. if the mention itself contains 'computer', 'custom' or other smiliar words, it is likely that software in referred to in general rather than to a specific one, and we can exclude that case. \n",
    "- one **very important** rule is that everything we take out of the middle match, we have to add to the left or right context in order to achieve consistent matches (except stuff we want to exclude in general). The question is how big the right context is supposed to be? A possible strategy could be to look at the words and see how much we would exclude. This is however not doable in snorkel. So we have to define a maxium right context or **expand it based on the actual match**. \n",
    "\n",
    "##### Individual Rules - Top 1\n",
    "- Top 1: Of course the rule does have a quite low recall, because it just considers a specific mentioning context (and this is also going to be true for all other rules in this scope) but it actually has a pretty good precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_nlp = spacy.load('en')\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "stopwords_left_context = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_growing_right_context(c, max_size=4):\n",
    "    version_number = re.compile(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)')\n",
    "    top1_head_words = ['statistical', \n",
    "                       'method', \n",
    "                       'procedure', \n",
    "                       'kit', \n",
    "                       'version',\n",
    "                       'Version',\n",
    "                       'v',\n",
    "                       'V',\n",
    "                       'v.',\n",
    "                       'V.',\n",
    "                       'ver.']\n",
    "    right_context = [x for x in get_right_tokens(c, window=max_size+1, attrib=\"lemmas\")]\n",
    "    for i,token in enumerate(right_context):\n",
    "        if i == max_size-1:\n",
    "            return right_context[max_size:max_size+1]\n",
    "        if (token in string.punctuation or \n",
    "            token in top1_head_words or\n",
    "            version_number.match(token)):\n",
    "            pass\n",
    "        else:\n",
    "            return right_context[i:i+1]\n",
    "        \n",
    "def LF_pan_top_1(c, stopwords):\n",
    "    '''use <> software'''\n",
    "    version_number = re.compile(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)')\n",
    "    top1_head_words = ['statistical', \n",
    "                       'method', \n",
    "                       'procedure', \n",
    "                       'kit', \n",
    "                       'version',\n",
    "                       'Version',\n",
    "                       'v',\n",
    "                       'V',\n",
    "                       'v.',\n",
    "                       'V.',\n",
    "                       'ver.']\n",
    "    left_context = ['use']\n",
    "    right_context = ['software']\n",
    "    tokens = [x.lower() for x in c[0].get_attrib_tokens()]\n",
    "    \n",
    "    if tokens[0] in stopwords or 'computer' in tokens or 'custom' in tokens or 'and' in tokens or tokens[-1] in ['statistical']:\n",
    "        return -1 \n",
    "    for tok in tokens:\n",
    "        if tok in string.punctuation or tok in top1_head_words or version_number.match(tok):\n",
    "            return -1\n",
    "    left_win_1 = [x for x in get_left_tokens(c, window=1, attrib=\"lemmas\")]\n",
    "    left_win_2 = [x for x in get_left_tokens(c, window=2, attrib=\"lemmas\")]\n",
    "    if len(left_win_2) > 0 and left_win_2[-1] in stopwords:\n",
    "        left_features = left_win_2[:-1]\n",
    "    else:\n",
    "        left_features = left_win_1\n",
    "    right_features = dynamic_growing_right_context(c)\n",
    "    if not right_features or len(left_context) != len(left_features) or len(right_context) != len(right_features):\n",
    "        return 0\n",
    "    for cont,feat in zip(left_context, left_features):\n",
    "        if cont != feat:\n",
    "            return 0\n",
    "    for cont,feat in zip(right_context, right_features):\n",
    "        if cont != feat:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spacy_nlp = spacy.load('en')\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "stopwords_left_context = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "lf = partial(LF_pan_top_1, stopwords=stopwords)\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in test_cands])\n",
    "tp, fp, tn, fn = scorer.score(test_marginals, set_unlabeled_as_neg=True, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Individual Rules - Top 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_pan_top_2(c,stopwords):\n",
    "    '''perform use <>'''\n",
    "    tokens = [x.lower() for x in c[0].get_attrib_tokens(a=\"lemmas\")]\n",
    "    negative_head_words = ['statistical', \n",
    "                           'software', \n",
    "                           'method', \n",
    "                           'procedure', \n",
    "                           'kit', \n",
    "                           'program', \n",
    "                           'tool', \n",
    "                           'toolbox',\n",
    "                           'version',\n",
    "                           'Version',\n",
    "                           'v',\n",
    "                           'V',\n",
    "                           'v.',\n",
    "                           'V.',\n",
    "                           'ver.']\n",
    "    for tok in tokens:\n",
    "        if tok in stopwords or tok in string.punctuation or tok in negative_head_words or re.match(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)', tok):\n",
    "            return 0 # -1\n",
    "    left_context = ['perform', 'use']\n",
    "    left_features = [x for x in get_left_tokens(c, window=2, attrib=\"lemmas\")]\n",
    "    #left_win_2 = [x for x in get_left_tokens(c, window=2, attrib=\"lemmas\")]\n",
    "    #left_win_3 = [x for x in get_left_tokens(c, window=3, attrib=\"lemmas\")]\n",
    "    #if len(left_win_3) > len(left_win_2) and left_win_3[-1] in stopwords:\n",
    "    #    left_features = left_win_3[:-1]\n",
    "    #else:\n",
    "    #    left_features = left_win_2\n",
    "    #left_features = left_win_2\n",
    "    if len(left_context) != len(left_features):\n",
    "        return 0\n",
    "    for c,f in zip(left_context, left_features):\n",
    "        if c != f:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lf = partial(LF_pan_top_2, stopwords=stopwords)\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in test_cands])\n",
    "tp, fp, tn, fn = scorer.score(test_marginals, set_unlabeled_as_neg=True, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Individual Rules - Top 3\n",
    "Output is **identical to rule top 2**. The mention context does always include the **be**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_pan_top_3(c, stopwords):\n",
    "    '''be perform use <>'''\n",
    "    tokens = [x.lower() for x in c[0].get_attrib_tokens(a=\"lemmas\")]\n",
    "    negative_head_words = ['statistical', \n",
    "                           'software', \n",
    "                           'method', \n",
    "                           'procedure', \n",
    "                           'kit', \n",
    "                           'program', \n",
    "                           'tool', \n",
    "                           'toolbox',\n",
    "                           'version',\n",
    "                           'Version',\n",
    "                           'v',\n",
    "                           'V',\n",
    "                           'v.',\n",
    "                           'V.',\n",
    "                           'ver.']\n",
    "    for tok in tokens:\n",
    "        if tok in stopwords or tok in string.punctuation or tok in negative_head_words or re.match(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)', tok):\n",
    "            return 0 # -1\n",
    "    left_context = ['be', 'perform', 'use']\n",
    "    left_features = [x for x in get_left_tokens(c, window=3, attrib=\"lemmas\")]\n",
    "    if len(left_context) != len(left_features):\n",
    "        return 0\n",
    "    for c,f in zip(left_context, left_features):\n",
    "        if c != f:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lf = partial(LF_pan_top_3, stopwords=stopwords)\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in test_cands])\n",
    "tp, fp, tn, fn = scorer.score(test_marginals, set_unlabeled_as_neg=True, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Individual Rules - Top 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_pan_top_4(c, stopwords):\n",
    "    '''analysis be perform use <>'''\n",
    "    tokens = [x.lower() for x in c[0].get_attrib_tokens(a=\"lemmas\")]\n",
    "    negative_head_words = ['statistical', \n",
    "                           'software', \n",
    "                           'method', \n",
    "                           'procedure', \n",
    "                           'kit', \n",
    "                           'program', \n",
    "                           'tool', \n",
    "                           'toolbox',\n",
    "                           'version',\n",
    "                           'Version',\n",
    "                           'v',\n",
    "                           'V',\n",
    "                           'v.',\n",
    "                           'V.',\n",
    "                           'ver.']\n",
    "    for tok in tokens:\n",
    "        if tok in stopwords or tok in string.punctuation or tok in negative_head_words or re.match(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)', tok):\n",
    "            return 0 # -1\n",
    "    left_context = ['analysis', 'be', 'perform', 'use']\n",
    "    left_features = [x for x in get_left_tokens(c, window=4, attrib=\"lemmas\")]\n",
    "    if len(left_context) != len(left_features):\n",
    "        return 0\n",
    "    for c,f in zip(left_context, left_features):\n",
    "        if c != f:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lf = partial(LF_pan_top_4, stopwords=stopwords)\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in test_cands])\n",
    "tp, fp, tn, fn = scorer.score(test_marginals, set_unlabeled_as_neg=True, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Individual Rules - Top 5 \n",
    "The big problem with this rule is that it also matches statistical tests which were performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_pan_top_5(c, stopwords):\n",
    "    '''analyze use <>'''\n",
    "    tokens = [x.lower() for x in c[0].get_attrib_tokens(a=\"lemmas\")]\n",
    "    negative_head_words = ['statistical', \n",
    "                           'software', \n",
    "                           'method', \n",
    "                           'procedure', \n",
    "                           'kit', \n",
    "                           'program', \n",
    "                           'tool', \n",
    "                           'toolbox',\n",
    "                           'version',\n",
    "                           'Version',\n",
    "                           'v',\n",
    "                           'V',\n",
    "                           'v.',\n",
    "                           'V.',\n",
    "                           'unpaired',\n",
    "                           'one-way',\n",
    "                           'two-way',\n",
    "                           'anova',\n",
    "                           't-test',\n",
    "                           'chi-square',\n",
    "                           'ver.']\n",
    "    for tok in tokens:\n",
    "        if tok in stopwords or tok in string.punctuation or tok in negative_head_words or re.match(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)', tok):\n",
    "            return 0 # -1\n",
    "    left_context = ['analyze', 'use']\n",
    "    left_features = [x for x in get_left_tokens(c, window=2, attrib=\"lemmas\")]\n",
    "    if len(left_context) != len(left_features):\n",
    "        return 0\n",
    "    for c,f in zip(left_context, left_features):\n",
    "        if c != f:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lf = partial(LF_pan_top_5, stopwords=stopwords)\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in test_cands])\n",
    "tp, fp, tn, fn = scorer.score(test_marginals, set_unlabeled_as_neg=True, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Individual Rules - Top 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_pan_top_6(c, stopwords):\n",
    "    '''analysis be perform with <>'''\n",
    "    tokens = [x.lower() for x in c[0].get_attrib_tokens(a=\"lemmas\")]\n",
    "    negative_head_words = ['statistical', \n",
    "                           'software', \n",
    "                           'method', \n",
    "                           'procedure', \n",
    "                           'kit', \n",
    "                           'program', \n",
    "                           'tool', \n",
    "                           'toolbox',\n",
    "                           'version',\n",
    "                           'Version',\n",
    "                           'v',\n",
    "                           'V',\n",
    "                           'v.',\n",
    "                           'V.',\n",
    "                           'ver.']\n",
    "    for tok in tokens:\n",
    "        if tok in stopwords or tok in string.punctuation or tok in negative_head_words or re.match(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)', tok):\n",
    "            return 0 # -1\n",
    "    left_context = ['analysis', 'be', 'perform', 'with']\n",
    "    left_features = [x for x in get_left_tokens(c, window=4, attrib=\"lemmas\")]\n",
    "    if len(left_context) != len(left_features):\n",
    "        return 0\n",
    "    for c,f in zip(left_context, left_features):\n",
    "        if c != f:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lf = partial(LF_pan_top_6, stopwords=stopwords)\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in test_cands])\n",
    "tp, fp, tn, fn = scorer.score(test_marginals, set_unlabeled_as_neg=True, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Individual Rules - Top 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_growing_context_top7(c, max_size=4, context=2, debug=False):\n",
    "    top7_head_words = ['version',\n",
    "                       'Version',\n",
    "                       'v',\n",
    "                       'V',\n",
    "                       'v.',\n",
    "                       'V.',\n",
    "                       'ver.']\n",
    "    version_number = re.compile(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)')\n",
    "    right_context = [x for x in get_right_tokens(c, window=max_size+context, attrib=\"lemmas\")]\n",
    "    if debug:\n",
    "        print(\"right context\")\n",
    "        print(right_context)\n",
    "    for i,token in enumerate(right_context):\n",
    "        if i == max_size-1:\n",
    "            if debug:\n",
    "                print(\"Return\")\n",
    "                print(right_context[max_size:max_size+context])\n",
    "            return right_context[max_size:max_size+context]\n",
    "        if (token in string.punctuation or \n",
    "            token in top7_head_words or\n",
    "            version_number.match(token)):\n",
    "            if debug:\n",
    "                print(\"passed up token \"+ token)\n",
    "            pass\n",
    "        else:\n",
    "            if debug:\n",
    "                print(\"Return\")\n",
    "                print(right_context[i:i+context])\n",
    "            return right_context[i:i+context]\n",
    "\n",
    "def LF_pan_top_7(c, stopwords):\n",
    "    '''<> statistical software'''\n",
    "    negative_head_words = ['statistical', \n",
    "                           'software', \n",
    "                           'method', \n",
    "                           'procedure', \n",
    "                           'kit', \n",
    "                           'program', \n",
    "                           'tool', \n",
    "                           'toolbox',\n",
    "                           'version',\n",
    "                           'Version',\n",
    "                           'v',\n",
    "                           'V',\n",
    "                           'v.',\n",
    "                           'V.',\n",
    "                           'ver.']\n",
    "    tokens = [x.lower() for x in c[0].get_attrib_tokens(a=\"lemmas\")]\n",
    "    for tok in tokens:\n",
    "        if tok == 'use' or tok in stopwords or tok in string.punctuation or tok in negative_head_words or re.match(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)', tok):\n",
    "            return 0 # -1\n",
    "    debug = False\n",
    "    #if tokens[0] == 'spss':\n",
    "    #    print(\"Tokens\")\n",
    "    #    print(tokens)\n",
    "    #    debug = True\n",
    "    right_context = ['statistical', 'software']\n",
    "    right_features = dynamic_growing_context_top7(c, debug=debug)\n",
    "    if not right_features or len(right_context) != len(right_features):\n",
    "        return 0\n",
    "    for c,f in zip(right_context, right_features):\n",
    "        if c != f:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = partial(LF_pan_top_7, stopwords=stopwords)\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in test_cands])\n",
    "tp, fp, tn, fn = scorer.score(test_marginals, set_unlabeled_as_neg=True, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Individual Rules - Top 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_pan_top_8(c, stopwords):\n",
    "    '''<> software be use'''\n",
    "    negative_head_words = ['statistical', \n",
    "                           'software', \n",
    "                           'method', \n",
    "                           'procedure', \n",
    "                           'kit', \n",
    "                           'program', \n",
    "                           'tool', \n",
    "                           'toolbox',\n",
    "                           'version',\n",
    "                           'Version',\n",
    "                           'v',\n",
    "                           'V',\n",
    "                           'v.',\n",
    "                           'V.',\n",
    "                           'ver.']\n",
    "    tokens = [x.lower() for x in c[0].get_attrib_tokens(a=\"lemmas\")]\n",
    "    for tok in tokens:\n",
    "        if tok == 'use' or tok in stopwords or tok in string.punctuation or tok in negative_head_words or re.match(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)', tok):\n",
    "            return 0 # -1\n",
    "    right_context = ['software', 'be', 'use']\n",
    "    right_features = dynamic_growing_context_top7(c, context=3, debug=False)\n",
    "    if not right_features or len(right_context) != len(right_features):\n",
    "        return 0\n",
    "    for c,f in zip(right_context, right_features):\n",
    "        if c != f:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = partial(LF_pan_top_6, stopwords=stopwords)\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in test_cands])\n",
    "tp, fp, tn, fn = scorer.score(test_marginals, set_unlabeled_as_neg=True, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Individual Rules - Top 9 \n",
    "In our case there was not a single tp from applying this rule, so it should probably be discarded instead of included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_pan_top_9(c, stopwords):\n",
    "    '''quantify use <>'''\n",
    "    tokens = [x.lower() for x in c[0].get_attrib_tokens(a=\"lemmas\")]\n",
    "    negative_head_words = ['statistical', \n",
    "                           'software', \n",
    "                           'method', \n",
    "                           'procedure', \n",
    "                           'kit', \n",
    "                           'program', \n",
    "                           'tool', \n",
    "                           'toolbox',\n",
    "                           'version',\n",
    "                           'Version',\n",
    "                           'v',\n",
    "                           'V',\n",
    "                           'v.',\n",
    "                           'V.',\n",
    "                           'ver.']\n",
    "    for tok in tokens:\n",
    "        if tok in stopwords or tok in string.punctuation or tok in negative_head_words or re.match(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)', tok):\n",
    "            return 0 # -1\n",
    "    left_context = ['quantify', 'use']\n",
    "    left_features = [x for x in get_left_tokens(c, window=2, attrib=\"lemmas\")]\n",
    "    if len(left_context) != len(left_features):\n",
    "        return 0\n",
    "    for c,f in zip(left_context, left_features):\n",
    "        if c != f:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = partial(LF_pan_top_9, stopwords=stopwords)\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in test_cands])\n",
    "tp, fp, tn, fn = scorer.score(test_marginals, set_unlabeled_as_neg=True, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Individual Rules - Top 10 \n",
    "Does not yield a single tp in our case, so it should rather be discarded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_pan_top_10(c, stopwords):\n",
    "    '''be caclulate use <>'''\n",
    "    tokens = [x.lower() for x in c[0].get_attrib_tokens(a=\"lemmas\")]\n",
    "    negative_head_words = ['statistical', \n",
    "                           'software', \n",
    "                           'method', \n",
    "                           'procedure', \n",
    "                           'kit', \n",
    "                           'program', \n",
    "                           'tool', \n",
    "                           'toolbox',\n",
    "                           'version',\n",
    "                           'Version',\n",
    "                           'v',\n",
    "                           'V',\n",
    "                           'v.',\n",
    "                           'V.',\n",
    "                           'ver.']\n",
    "    for tok in tokens:\n",
    "        if tok in stopwords or tok in string.punctuation or tok in negative_head_words or re.match(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)', tok):\n",
    "            return 0 # -1\n",
    "    left_context = ['be', 'calculate', 'use']\n",
    "    left_features = [x for x in get_left_tokens(c, window=3, attrib=\"lemmas\")]\n",
    "    if len(left_context) != len(left_features):\n",
    "        return 0\n",
    "    for c,f in zip(left_context, left_features):\n",
    "        if c != f:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lf = partial(LF_pan_top_10, stopwords=stopwords)\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in test_cands])\n",
    "tp, fp, tn, fn = scorer.score(test_marginals, set_unlabeled_as_neg=True, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duck et al.'s BioNerDS and further similar points:\n",
    "- Head Nouns, basically we are considering keywords appearing with software: **software, package, tool, toolkit, program, framework, web-service, ..**\n",
    "- Version Number, many software mentions come with a Version number, if they do this can be a strong hint.\n",
    "- References and URLs (footnotes), software can often be cited on a Reference to the publisher could be given. However this reference might be hidden in footnotes. \n",
    "- Mention of the Developer, this is especially found with commercial software. In this style the producer is mentioned in brackets behind the software)\n",
    "- Duck et al. also use negative head nouns.\n",
    "\n",
    "#### Considerations\n",
    "The rules are not quite as clear as the ones provided by Pan et al., therefore we have to make some more considerations on how to best apply them.\n",
    "\n",
    "Head Nouns should appear right around the word, it is possilbe to be in the left as well as the right context. There might be some space between the artefact name and the head noun. For example if we consider that the artefact is followed by 'version 2.0 software' this would be two tokens and we have to examine a context of three. The question is should a larger context be weighted lower than a smaller one?  \n",
    "\n",
    "We always consider version numbers to stand behind the software. However the identification of a proper version number is not as easy at it seems. V2, Version 2, Version 2.0, v 2.0, etc. This requires digging up or creation of a suited rule/regex which nicely covers all of this stuff. \n",
    "\n",
    "URLs following in the right context of a word are easily identified because they are quite easy to discriminate from normal text. References are more difficult, but we will probably mainly match them over matching `[num]`. However, references should probably be combined with another mechanism because they are quite a weak indicator in a scientific article. \n",
    "\n",
    "Finding a reference to the publisher should be complex, but should be possible following the same principle, except that regex matching is necessary in the individual steps. \n",
    "\n",
    "#### 3 Rules\n",
    "We will try out three rules based on the contexts reported by Duck et al.\n",
    "\n",
    "##### Head Nouns\n",
    "Looking for positive head nouns in the right context (it is more common for the right context to contain head nouns). \n",
    "\n",
    "One main source of fps is that software is also partially matched. When we apply POS tags on the left context in order to see if left are more nouns we can improve peformance.\n",
    "\n",
    "One 'problem' that is still given in the data is the matching of abbreviations instead of the full name. But since this can still be considered as correct matching we will not remove it to increase the quality of the data. The case can be illustrated in the following example:\n",
    "`First, genotypes from the exomes were entered into the Copy Number Inference from Exome Reads (CoNIFER) package [74].` where we match `CoNIFER` instead of `Copy Number Inference from Exome Reads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_next_right_word(c, max_size=6):\n",
    "    version_number = re.compile(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)')\n",
    "    positive_head_nouns = [\n",
    "        'software',\n",
    "        'package',\n",
    "        'program', \n",
    "        'tool', \n",
    "        'toolbox',\n",
    "        'web-service',\n",
    "        'spreadsheet'\n",
    "    ]\n",
    "    top1_head_words = ['statistical', \n",
    "                       'method', \n",
    "                       'procedure', \n",
    "                       'kit', \n",
    "                       'version',\n",
    "                       'Version',\n",
    "                       'v',\n",
    "                       'V',\n",
    "                       'v.',\n",
    "                       'V.',\n",
    "                       'ver.']\n",
    "    right_context = [x for x in get_right_tokens(c, window=max_size, attrib=\"lemmas\")]\n",
    "    for i,token in enumerate(right_context):\n",
    "        if token in positive_head_nouns:\n",
    "            return 1\n",
    "        elif (token in string.punctuation or \n",
    "            token in top1_head_words or\n",
    "            version_number.match(token)):\n",
    "            pass\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "def LF_software_head_nouns(c, stopwords):\n",
    "    negative_head_words = ['statistical', \n",
    "                           'software', \n",
    "                           'method', \n",
    "                           'procedure', \n",
    "                           'kit', \n",
    "                           'program', \n",
    "                           'tool', \n",
    "                           'toolbox',\n",
    "                           'version',\n",
    "                           'Version',\n",
    "                           'v',\n",
    "                           'V',\n",
    "                           'v.',\n",
    "                           'V.',\n",
    "                           'ver.']\n",
    "    tokens = [x.lower() for x in c[0].get_attrib_tokens(a=\"lemmas\")]\n",
    "    for tok in tokens:\n",
    "        if tok in ['software', 'program', 'tool', 'computer', 'custom'] or tok in stopwords or tok in string.punctuation or tok in negative_head_words or re.match(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)', tok):\n",
    "            return -1\n",
    "    poses = [x for x in c[0].get_attrib_tokens(a=\"pos_tags\")]\n",
    "    for pos in poses:\n",
    "        if pos not in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "            return -1 # 0\n",
    "    left_context = [x for x in get_left_tokens(c, window=1, attrib=\"pos_tags\")]\n",
    "    left_words = [x for x in get_left_tokens(c, window=1, attrib=\"words\")]\n",
    "    if left_context and left_context[0] in ['nn', 'nns', 'nnp', 'nnps']:\n",
    "        return 0\n",
    "    res = get_normalized_next_right_word(c)\n",
    "    if res:\n",
    "        return res\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = partial(LF_software_head_nouns, stopwords=stopwords)\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in test_cands])\n",
    "tp, fp, tn, fn = scorer.score(test_marginals, set_unlabeled_as_neg=True, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Version Numbers\n",
    "Looking for version numbers in the right context. Version numbers almost exclusively appear right of the software mention. \n",
    "\n",
    "Applying the left context rule that was introduced above here actual hurts performance somewhat while managing further improvent on the number of fps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_version_number(c):\n",
    "    version_number = re.compile(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)')\n",
    "    simple_float = re.compile(r'^0\\.\\d{1,3}$')\n",
    "    common_measures = ['nm', 'Âµm', 'mm', 'cm', 'dm', 'm', 'km', 'mg', 'g', 'kg', 'ml', 'l', 's', 'h', 'y']\n",
    "    restrictive_version_number = re.compile(r'^(v|V|v.|V.)?(\\d{1,3}\\.)?(\\d{1,3}\\.)(\\d{1,3})$')\n",
    "    lemmas = [x.lower() for x in c[0].get_attrib_tokens(a=\"lemmas\")]\n",
    "    pos_tags = [x for x in c[0].get_attrib_tokens(a=\"pos_tags\")]\n",
    "    for lem in lemmas:\n",
    "        if (len(lem) <= 1 and not lem.isalpha()) or lem in ['v', 'V', 'v.', 'V.', 'ver.', 'Ver.', 'version', 'Version'] or lem in ['software', 'package', 'program'] or lem == 'ph':\n",
    "            return -1\n",
    "    for pos in pos_tags:\n",
    "        if pos not in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "            return -1\n",
    "    #left_context = [x for x in get_left_tokens(c, window=1, attrib=\"pos_tags\")]\n",
    "    #left_words = [x for x in get_left_tokens(c, window=1, attrib=\"words\")]\n",
    "    #if left_context and left_context[0] in ['nn', 'nns', 'nnp', 'nnps']:\n",
    "    #    return -1\n",
    "    right_context = [x for x in get_right_tokens(c, window=4, attrib=\"lemmas\")]\n",
    "    to_examine = 0\n",
    "    if not right_context:\n",
    "        return 0\n",
    "    if right_context[0] in ['(']:#,'[','{']: #TODO: also exclude software, package, software package, etc.\n",
    "        to_examine = 1\n",
    "    if len(right_context) > 1 and right_context[to_examine] in ['v', 'V', 'v.', 'V.', 'ver.', 'Ver.', 'version', 'Version']:\n",
    "        if len(right_context) > 2:\n",
    "            potential_version_number = right_context[to_examine+1]\n",
    "            if version_number.match(potential_version_number):\n",
    "                return 1\n",
    "        return 0\n",
    "    if len(right_context) > 1 and not simple_float.match(right_context[to_examine]) and restrictive_version_number.match(right_context[to_examine]):\n",
    "        if len(right_context) > 2:\n",
    "            next_right_context = right_context[to_examine+1]\n",
    "            if next_right_context in ['%'] or next_right_context in common_measures:\n",
    "                return -1\n",
    "        return 1\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = LF_version_number\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in test_cands])\n",
    "tp, fp, tn, fn = scorer.score(test_marginals, set_unlabeled_as_neg=True, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reference/URL/Developer\n",
    "\n",
    "Reference: We are not doing references because they are to ambiguous in scientific studies and do no serve as a solid feature. (Examining our development set confirms that.)\n",
    "\n",
    "URL: Does not work to well, but might make a nice addition to other rules.\n",
    "\n",
    "Developer: We are looking for constructs like: `(SPSS, Chicago, IL, USA)`, `(v. 15 IBM, Chicago, IL, USA,)` or `(SAS Institute, Cary, North Carolina)` which should be easy to identify in a text. The basic construction of the rule should be equal to extracting URLs. Just the match between the brackets has to be refined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_url(c):\n",
    "    # The following regex certainly matches, but that might also work in a far less complex way..\n",
    "    url_regex = re.compile(r\"^((http(s)?:\\/\\/www\\.)|(http(s)?:\\/\\/)|(www\\.))[a-z\\.-]+[\\w\\-\\._~:/?#[\\]@!\\$&'\\(\\)\\*\\+,;=.]+$\")\n",
    "    version_indicators = ['v', 'V', 'v.', 'V.', 'ver.', 'Ver.', 'version', 'Version']\n",
    "    version_number = re.compile(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)')\n",
    "    positive_head_nouns = [\n",
    "        'software',\n",
    "        'package',\n",
    "        'program', \n",
    "        'tool', \n",
    "        'toolbox',\n",
    "        'web-service',\n",
    "        'spreadsheet'\n",
    "    ]\n",
    "    lemmas = [x.lower() for x in c[0].get_attrib_tokens(a=\"lemmas\")]\n",
    "    pos_tags = [x for x in c[0].get_attrib_tokens(a=\"pos_tags\")]\n",
    "    for lem in lemmas:\n",
    "        if (len(lem) <= 1 and not lem.isalpha()) or version_number.match(lem) or lem in version_indicators or lem in positive_head_nouns or lem in ['computer']:\n",
    "            return -1\n",
    "    for pos in pos_tags:\n",
    "        if pos not in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "            return  -1\n",
    "    left_context = [x for x in get_left_tokens(c, window=1, attrib=\"pos_tags\")]\n",
    "    left_words = [x for x in get_left_tokens(c, window=1, attrib=\"words\")]\n",
    "    if left_context and left_context[0] in ['nn', 'nns', 'nnp', 'nnps']:\n",
    "        return 0 # -1\n",
    "    # In principle we just want to look at the entire right context and decide for our selfs how big it should be\n",
    "    right_context = [x for x in get_right_tokens(c, window=15, attrib=\"lemmas\")]\n",
    "    right_context_size = len(right_context)\n",
    "    first_token_to_consider = 0\n",
    "    while (first_token_to_consider < right_context_size and \n",
    "           (right_context[first_token_to_consider] in version_indicators or \n",
    "            right_context[first_token_to_consider] in positive_head_nouns or right_context[first_token_to_consider] in ['computer'] or \n",
    "            version_number.match(right_context[first_token_to_consider]))):\n",
    "        first_token_to_consider += 1 \n",
    "        \n",
    "    if first_token_to_consider == right_context_size or right_context[first_token_to_consider] != '(':\n",
    "        return 0\n",
    "    else:\n",
    "        remaining_right_context = right_context[first_token_to_consider+1:]\n",
    "        while remaining_right_context:\n",
    "            tok = remaining_right_context.pop(0)\n",
    "            if tok == ')':\n",
    "                return 0\n",
    "            if url_regex.match(tok):\n",
    "                return 1\n",
    "        return 0 \n",
    "\n",
    "def LF_developer(c):\n",
    "    version_number = re.compile(r'(v|V|v.|V.)?(\\d+\\.)?(\\d+\\.)?(\\d+)')\n",
    "    developer_version_addition = ['v.', 'ver.', 'version']\n",
    "    version_indicators = ['v', 'V', 'v.', 'V.', 'ver.', 'Ver.', 'version', 'Version']\n",
    "    positive_head_nouns = [\n",
    "        'software',\n",
    "        'package',\n",
    "        'program', \n",
    "        'tool', \n",
    "        'toolbox',\n",
    "        'web-service',\n",
    "        'spreadsheet'\n",
    "    ]\n",
    "    lemmas = [x.lower() for x in c[0].get_attrib_tokens(a=\"lemmas\")]\n",
    "    pos_tags = [x for x in c[0].get_attrib_tokens(a=\"pos_tags\")]\n",
    "    for lem in lemmas:\n",
    "        if (len(lem) <= 1 and not lem.isalpha()) or version_number.match(lem) or lem in version_indicators or lem in positive_head_nouns or lem in ['computer']:\n",
    "            return -1\n",
    "    for pos in pos_tags:\n",
    "        if pos not in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "            return -1\n",
    "    left_context = [x for x in get_left_tokens(c, window=1, attrib=\"pos_tags\")]\n",
    "    left_words = [x for x in get_left_tokens(c, window=1, attrib=\"words\")]\n",
    "    if left_context and left_context[0] in ['nn', 'nns', 'nnp', 'nnps']:\n",
    "        return 0# -1\n",
    "    # In principle we just want to look at the entire right context and decide for our selfs how big it should be\n",
    "    right_context = [x for x in get_right_tokens(c, window=20, attrib=\"lemmas\")]\n",
    "    right_context_size = len(right_context)\n",
    "    first_token_to_consider = 0\n",
    "    while (first_token_to_consider < right_context_size and \n",
    "           (right_context[first_token_to_consider] in version_indicators or \n",
    "            right_context[first_token_to_consider] in positive_head_nouns or right_context[first_token_to_consider] in ['computer'] or \n",
    "            version_number.match(right_context[first_token_to_consider]))):\n",
    "        first_token_to_consider += 1 \n",
    "    # Behave different for here: We want to examine the context, therefore we first extract the entire context \n",
    "    # by looking for the closing bracket first. \n",
    "    \n",
    "    if first_token_to_consider == right_context_size or right_context[first_token_to_consider] != '(':\n",
    "        return 0\n",
    "    else:\n",
    "        remaining_tokens = right_context[first_token_to_consider+1:]\n",
    "        #remaining_words = right_words[first_token_to_consider+1:]\n",
    "        last_token_to_consider = -1\n",
    "        for i,tok in enumerate(remaining_tokens):\n",
    "            if tok == ')':\n",
    "                last_token_to_consider = i \n",
    "                break\n",
    "        if last_token_to_consider < 0:\n",
    "            return 0\n",
    "        else: \n",
    "            remaining_tokens = remaining_tokens[:last_token_to_consider]\n",
    "            #remaining_words = remaining_words[:last_token_to_consider]\n",
    "            # Here we perform the actual test\n",
    "            for tok in remaining_tokens:\n",
    "                if tok in developer_version_addition or tok in ['inc', 'ltd', 'corp', 'apply']:\n",
    "                    return 1\n",
    "                if tok in ['such', 'i.e', 'e.g']:\n",
    "                    return -1\n",
    "            #for tok in remaining_words:\n",
    "            #    if tok in us_states:\n",
    "            #        return 1\n",
    "            token_split = [[]]\n",
    "            for i in remaining_tokens:\n",
    "                if i in [',', ';']:\n",
    "                    token_split.append([])\n",
    "                else:\n",
    "                    token_split[-1].append(i)\n",
    "            \n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = LF_developer\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in test_cands])\n",
    "tp, fp, tn, fn = scorer.score(test_marginals, set_unlabeled_as_neg=True, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = LF_url\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in test_cands])\n",
    "tp, fp, tn, fn = scorer.score(test_marginals, set_unlabeled_as_neg=True, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SentenceNgramViewer(fp, session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}