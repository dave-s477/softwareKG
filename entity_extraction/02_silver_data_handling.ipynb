{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silver Standard handling\n",
    "Split SSC into smaller chunks to efficiently perform pretraining on it. \n",
    "We have to look up how much silver data is overall available. \n",
    "Since the dataset is extremely large its not feasible to train on all articles for each epoch. \n",
    "Instead we train one epoch on all positive samples and randomly sampled negative samples until we saw all negative samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = {\n",
    "    '../../SoSciSoCi-SSC/data/SSC_pos_samples_data.txt': [],\n",
    "    '../../SoSciSoCi-SSC/data/SSC_pos_samples_labels.txt': [],\n",
    "    '../../SoSciSoCi-SSC/data/SSC_neg_samples_data.txt': [],\n",
    "    '../../SoSciSoCi-SSC/data/SSC_neg_samples_labels.txt': []\n",
    "}\n",
    "for dataset in buckets.keys():\n",
    "    with open(dataset, 'r') as data:\n",
    "        for line in data:\n",
    "            buckets[dataset].append(line)\n",
    "\n",
    "for dataset in buckets.keys():\n",
    "    print(len(buckets[dataset]))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Based on the size of our sets we decided to split it into 12 sets, where one positive sample is always accompanied by one negative sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "NUM_SILVER_TRAIN = 12\n",
    "\n",
    "for i in range(NUM_SILVER_TRAIN):\n",
    "    print(\"Creating set {}\".format(i))\n",
    "    with open('../data/merged_SSC_data_ep{}.txt'.format(i), 'w') as merged_d, open('../data/merged_SSC_labels_ep{}.txt'.format(i), 'w') as merged_l:\n",
    "        for idx, (x, y) in enumerate(zip(buckets['../../SoSciSoCi-SSC/data/SSC_pos_samples_data.txt'], buckets['../../SoSciSoCi-SSC/data/SSC_pos_samples_labels.txt'])):\n",
    "            if idx % 50000 == 0:\n",
    "                print(\"At index {}\".format(idx))\n",
    "            merged_d.write(x)\n",
    "            merged_l.write(y)\n",
    "            index_to_pop = random.randint(0, len(buckets['../../SoSciSoCi-SSC/data/SSC_neg_samples_data.txt'])-1)\n",
    "            text_string = buckets['../../SoSciSoCi-SSC/data/SSC_neg_samples_data.txt'].pop(index_to_pop)\n",
    "            merged_d.write(text_string)\n",
    "            labels_string = \" \"\n",
    "            for a in range(len(text_string.split())):\n",
    "                labels_string += \"O \"\n",
    "            labels_string += '\\n'\n",
    "            merged_l.write(labels_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A small number of negative samples gets left out of this sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(buckets['data/neg_silver_samples_data.txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a split for optimizing the pre-training\n",
    "\n",
    "This split is intended to just test how well the model is able to learn on the silver standard and to predict on the silver standard. \n",
    "For this purpose the silver standard is split into a train and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "size_of_silver_set = 25000\n",
    "\n",
    "print(\"Creating the silver devel set\")\n",
    "with open('../data/merged_SSC_opt_test_data.txt', 'w') as merged_d, open('../data/merged_SSC_opt_test_labels.txt', 'w') as merged_l:\n",
    "    for idx in range(size_of_silver_set):\n",
    "        if idx % 50000 == 0:\n",
    "            print(\"At index {}\".format(idx))\n",
    "        pos_index_to_pop = random.randint(0, len(buckets['../../SoSciSoCi-SSC/data/SSC_pos_samples_data.txt'])-1)\n",
    "        neg_index_to_pop = random.randint(0, len(buckets['../../SoSciSoCi-SSC/data/SSC_neg_samples_data.txt'])-1)\n",
    "        pos_text_string = buckets['../../SoSciSoCi-SSC/data/SSC_pos_samples_data.txt'].pop(pos_index_to_pop)\n",
    "        pos_text_label = buckets['../../SoSciSoCi-SSC/data/SSC_pos_samples_labels.txt'].pop(pos_index_to_pop)\n",
    "        merged_d.write(pos_text_string)\n",
    "        merged_l.write(pos_text_label)\n",
    "        neg_text_string = buckets['../../SoSciSoCi-SSC/data/SSC_neg_samples_data.txt'].pop(neg_index_to_pop)\n",
    "        merged_d.write(neg_text_string)\n",
    "        labels_string = \" \"\n",
    "        for a in range(len(neg_text_string.split())):\n",
    "            labels_string += \"O \"\n",
    "        labels_string += '\\n'\n",
    "        merged_l.write(labels_string)\n",
    "\n",
    "NUM_SILVER_TRAIN = 14\n",
    "\n",
    "for i in range(NUM_SILVER_TRAIN):\n",
    "    print(\"Creating set {}\".format(i))\n",
    "    with open('../data/merged_SSC_opt_train_data_ep{}.txt'.format(i), 'w') as merged_d, open('../data/merged_SSC_opt_train_labels_ep{}.txt'.format(i), 'w') as merged_l:\n",
    "        for idx, (x, y) in enumerate(zip(buckets['../../SoSciSoCi-SSC/data/SSC_pos_samples_data.txt'], buckets['../../SoSciSoCi-SSC/data/SSC_pos_samples_labels.txt'])):\n",
    "            if idx % 50000 == 0:\n",
    "                print(\"At index {}\".format(idx))\n",
    "            merged_d.write(x)\n",
    "            merged_l.write(y)\n",
    "            index_to_pop = random.randint(0, len(buckets['../../SoSciSoCi-SSC/data/SSC_neg_samples_data.txt'])-1)\n",
    "            text_string = buckets['../../SoSciSoCi-SSC/data/SSC_neg_samples_data.txt'].pop(index_to_pop)\n",
    "            merged_d.write(text_string)\n",
    "            labels_string = \" \"\n",
    "            for a in range(len(text_string.split())):\n",
    "                labels_string += \"O \"\n",
    "            labels_string += '\\n'\n",
    "            merged_l.write(labels_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}