#!/bin/bash

# Pretraining
python perform_training.py --learning-rate 0.0020 --learning-decay 0 --dropout-rate 0.5 --epochs 1 --train-set silver_train_0 --test-set gold_devel --save-name pre_training_0 --train train --log-name pre_training --log-training 1 --custom-eval 1 --sample-weights 0.1 --lstm-size 200
python perform_training.py --learning-rate 0.0019 --learning-decay 0 --dropout-rate 0.5 --epochs 1 --train-set silver_train_1 --test-set gold_devel --save-name pre_training_1 --train train --log-name pre_training --log-training 1 --custom-eval 1 --sample-weights 0.1 --lstm-size 200 --global_epoch 1 --checkpoint pre_training_0
#python perform_training.py --learning-rate 0.0018 --learning-decay 0 --dropout-rate 0.5 --epochs 1 --train-set silver_train_1 --test-set gold_devel --save-name pre_training_2 --train train --log-name pre_training --log-training 1 --custom-eval 1 --sample-weights 0.1 --lstm-size 200 --global_epoch 2 --checkpoint pre_training_1
#python perform_training.py --learning-rate 0.0017 --learning-decay 0 --dropout-rate 0.5 --epochs 1 --train-set silver_train_1 --test-set gold_devel --save-name pre_training_3 --train train --log-name pre_training --log-training 1 --custom-eval 1 --sample-weights 0.1 --lstm-size 200 --global_epoch 3 --checkpoint pre_training_2
#python perform_training.py --learning-rate 0.0016 --learning-decay 0 --dropout-rate 0.5 --epochs 1 --train-set silver_train_1 --test-set gold_devel --save-name pre_training_4 --train train --log-name pre_training --log-training 1 --custom-eval 1 --sample-weights 0.1 --lstm-size 200 --global_epoch 4 --checkpoint pre_training_3
#python perform_training.py --learning-rate 0.0015 --learning-decay 0 --dropout-rate 0.5 --epochs 1 --train-set silver_train_1 --test-set gold_devel --save-name pre_training_5 --train train --log-name pre_training --log-training 1 --custom-eval 1 --sample-weights 0.1 --lstm-size 200 --global_epoch 5 --checkpoint pre_training_4
#python perform_training.py --learning-rate 0.0014 --learning-decay 0 --dropout-rate 0.5 --epochs 1 --train-set silver_train_1 --test-set gold_devel --save-name pre_training_6 --train train --log-name pre_training --log-training 1 --custom-eval 1 --sample-weights 0.1 --lstm-size 200 --global_epoch 6 --checkpoint pre_training_5
#python perform_training.py --learning-rate 0.0013 --learning-decay 0 --dropout-rate 0.5 --epochs 1 --train-set silver_train_1 --test-set gold_devel --save-name pre_training_7 --train train --log-name pre_training --log-training 1 --custom-eval 1 --sample-weights 0.1 --lstm-size 200 --global_epoch 7 --checkpoint pre_training_6
#python perform_training.py --learning-rate 0.0012 --learning-decay 0 --dropout-rate 0.5 --epochs 1 --train-set silver_train_1 --test-set gold_devel --save-name pre_training_8 --train train --log-name pre_training --log-training 1 --custom-eval 1 --sample-weights 0.1 --lstm-size 200 --global_epoch 8 --checkpoint pre_training_7
#python perform_training.py --learning-rate 0.0011 --learning-decay 0 --dropout-rate 0.5 --epochs 1 --train-set silver_train_1 --test-set gold_devel --save-name pre_training_9 --train train --log-name pre_training --log-training 1 --custom-eval 1 --sample-weights 0.1 --lstm-size 200 --global_epoch 9 --checkpoint pre_training_8
#python perform_training.py --learning-rate 0.0010 --learning-decay 0 --dropout-rate 0.5 --epochs 1 --train-set silver_train_1 --test-set gold_devel --save-name pre_training_10 --train train --log-name pre_training --log-training 1 --custom-eval 1 --sample-weights 0.1 --lstm-size 200 --global_epoch 10 --checkpoint pre_training_9
#python perform_training.py --learning-rate 0.0010 --learning-decay 0 --dropout-rate 0.5 --epochs 1 --train-set silver_train_1 --test-set gold_devel --save-name pre_training_11 --train train --log-name pre_training --log-training 1 --custom-eval 1 --sample-weights 0.1 --lstm-size 200 --global_epoch 11 --checkpoint pre_training_10

# and also: train on SSC -> predict GSC test
# here we assume that the SSC model is pre-trained and do not actually train anything more!
python perform_training.py --learning-rate 0.0015 --learning-decay 0.00007 --dropout-rate 0.4 --epochs 1 --train-set gold_train_with_pos --test-set gold_test --save-name pre_training_1 --train test --log-name pre_training_test --sample-weights 0.1 --log-training 1 --custom-eval 1 --lstm-size 100 --checkpoint pre_training_1