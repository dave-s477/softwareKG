{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Managing the data used for training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from os import listdir, remove, makedirs\n",
    "from os.path import join, exists\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/SoSciSoCi_train_dev_test_split.json', 'r') as json_file:\n",
    "    train_test_split_unique = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We have to clean up the SoSci data a little and can then split it into the distinct sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sosci(name, include_pos_samples=False):\n",
    "    if include_pos_samples:\n",
    "        train_name = '_train_with_pos_'\n",
    "    else:\n",
    "        train_name = '_train_no_pos_'\n",
    "    with open('../data/{}_bio.txt'.format(name), 'r') as read_file, \\\n",
    "    open('../data/positive_samples_bio.txt', 'r') as pos_sample_file, \\\n",
    "    open('../data/{}{}data.txt'.format(name, train_name), 'w') as text_file_train, \\\n",
    "    open('../data/{}{}labels.txt'.format(name, train_name), 'w') as labels_file_train, \\\n",
    "    open('../data/{}_devel_data.txt'.format(name), 'w') as text_file_devel, \\\n",
    "    open('../data/{}_devel_labels.txt'.format(name), 'w') as labels_file_devel, \\\n",
    "    open('../data/{}_test_data.txt'.format(name), 'w') as text_file_test, \\\n",
    "    open('../data/{}_test_labels.txt'.format(name), 'w') as labels_file_test:\n",
    "        current_line = ''\n",
    "        current_labels = ''\n",
    "        current_file = ''\n",
    "        for line in read_file:\n",
    "            if line.startswith('-DOCSTART-'):\n",
    "                current_file = line.split(':')[1].rstrip('\\n')\n",
    "                if current_file in train_test_split_unique['train']:\n",
    "                    set_to_put = 'train'\n",
    "                elif current_file in train_test_split_unique['devel']:\n",
    "                    set_to_put = 'devel'\n",
    "                elif current_file in train_test_split_unique['test']:\n",
    "                    set_to_put = 'test'\n",
    "                else:\n",
    "                    print(\"Unknown file. This should be an error.\")\n",
    "            elif line == '\\n':\n",
    "                if set_to_put == 'train':\n",
    "                    text_file_train.writelines(current_line + '\\n')\n",
    "                    labels_file_train.writelines(current_labels + '\\n')\n",
    "                elif set_to_put == 'devel':\n",
    "                    text_file_devel.writelines(current_line + '\\n')\n",
    "                    labels_file_devel.writelines(current_labels + '\\n')\n",
    "                elif set_to_put == 'test':\n",
    "                    text_file_test.writelines(current_line + '\\n')\n",
    "                    labels_file_test.writelines(current_labels + '\\n')\n",
    "                else:\n",
    "                    print(\"Unknown file. This should be an error.\")\n",
    "                current_line = ''\n",
    "                current_labels = ''\n",
    "            else:\n",
    "                sep = line.split()\n",
    "                current_line += sep[0] + ' '\n",
    "                current_labels += sep[1] + ' '\n",
    "                \n",
    "        if include_pos_samples:\n",
    "            current_line = ''\n",
    "            current_labels = ''\n",
    "            current_file = ''\n",
    "            for line in pos_sample_file:\n",
    "                if line.startswith('-DOCSTART-'):\n",
    "                    continue\n",
    "                elif line == '\\n':\n",
    "                    text_file_train.writelines(current_line + '\\n')\n",
    "                    labels_file_train.writelines(current_labels + '\\n')\n",
    "                    current_line = ''\n",
    "                    current_labels = ''\n",
    "                else:\n",
    "                    sep = line.split()\n",
    "                    current_line += sep[0] + ' '\n",
    "                    current_labels += sep[1] + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "clean_up_sosci('SoSciSoCi', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling the data used for reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SETS = 40\n",
    "reasoning_files = listdir('../data/R_loading/SENTS')\n",
    "print(\"Reasoning on {} articles.\".format(len(reasoning_files)))\n",
    "\n",
    "if not exists('reasoning_sets'):\n",
    "    makedirs('reasoning_sets')\n",
    "\n",
    "files_per_set = math.ceil(len(reasoning_files)/NUM_SETS)\n",
    "\n",
    "for i in range(NUM_SETS):\n",
    "    files = reasoning_files[i*files_per_set:(i+1)*files_per_set]\n",
    "    pickle.dump(files, open(\"reasoning_sets/reasoning_set_{}.p\".format(i), \"wb\")) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_2.0)",
   "language": "python",
   "name": "nlp_2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}