{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing the data used for training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from os import listdir, remove\n",
    "from os.path import join, exists\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/sosci_train_dev_test_split.json', 'r') as json_file:\n",
    "    train_test_split_unique = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to clean up the SoSci data a little and can then split it into the distinct sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sosci(name, version, include_pos_samples=False, big_train=False):\n",
    "    if include_pos_samples:\n",
    "        train_name = '_train_with_pos_'\n",
    "    else:\n",
    "        train_name = '_train_no_pos_'\n",
    "    with open('data/{}_raw_{}.txt'.format(name, version), 'r') as read_file, \\\n",
    "    open('data/sosci_pos_sample_output.txt', 'r') as pos_sample_file, \\\n",
    "    open('data/{}{}data.txt'.format(name, train_name), 'w') as text_file_train, \\\n",
    "    open('data/{}{}labels.txt'.format(name, train_name), 'w') as labels_file_train, \\\n",
    "    open('data/{}_devel_data.txt'.format(name), 'w') as text_file_devel, \\\n",
    "    open('data/{}_devel_labels.txt'.format(name), 'w') as labels_file_devel, \\\n",
    "    open('data/{}_test_data.txt'.format(name), 'w') as text_file_test, \\\n",
    "    open('data/{}_test_labels.txt'.format(name), 'w') as labels_file_test:\n",
    "        current_line = ''\n",
    "        current_labels = ''\n",
    "        current_file = ''\n",
    "        for line in read_file:\n",
    "            if line.startswith('-DOCSTART-'):\n",
    "                current_file = line.split(':')[1].rstrip('\\n')\n",
    "                if current_file in train_test_split_unique['train']:\n",
    "                    set_to_put = 'train'\n",
    "                elif current_file in train_test_split_unique['devel']:\n",
    "                    set_to_put = 'devel'\n",
    "                elif current_file in train_test_split_unique['test']:\n",
    "                    set_to_put = 'test'\n",
    "                    sosci_data_split['test'].append(current_file)\n",
    "            elif line == '\\n':\n",
    "                if set_to_put == 'train':\n",
    "                    text_file_train.writelines(current_line + '\\n')\n",
    "                    labels_file_train.writelines(current_labels + '\\n')\n",
    "                elif set_to_put == 'devel':\n",
    "                    text_file_devel.writelines(current_line + '\\n')\n",
    "                    labels_file_devel.writelines(current_labels + '\\n')\n",
    "                elif set_to_put == 'test':\n",
    "                    text_file_test.writelines(current_line + '\\n')\n",
    "                    labels_file_test.writelines(current_labels + '\\n')\n",
    "                else:\n",
    "                    print(\"Unknown file. This should be an error.\")\n",
    "                current_line = ''\n",
    "                current_labels = ''\n",
    "            else:\n",
    "                sep = line.split()\n",
    "                current_line += sep[0] + ' '\n",
    "                current_labels += sep[1] + ' '\n",
    "                \n",
    "        if include_pos_samples:\n",
    "            current_line = ''\n",
    "            current_labels = ''\n",
    "            current_file = ''\n",
    "            for line in pos_sample_file:\n",
    "                if line.startswith('-DOCSTART-'):\n",
    "                    continue\n",
    "                elif line == '\\n':\n",
    "                    text_file_train.writelines(current_line + '\\n')\n",
    "                    labels_file_train.writelines(current_labels + '\\n')\n",
    "                    current_line = ''\n",
    "                    current_labels = ''\n",
    "                else:\n",
    "                    sep = line.split()\n",
    "                    current_line += sep[0] + ' '\n",
    "                    current_labels += sep[1] + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "clean_up_sosci('sosci', 2, True, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_2.0)",
   "language": "python",
   "name": "nlp_2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
